{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68d858da-315e-4c32-ae49-a072399094e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd10d2e-5529-419e-9bcc-3eec9ebda317",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [-f F] [-t T] [-n N] [-p P] [-c C] [-k K]\n",
      "               [--absolute_freqs] [--z_scores] [-s S [S ...]] [-x X]\n",
      "               [--sampling] [--sample_units SAMPLE_UNITS]\n",
      "               [--sample_size SAMPLE_SIZE] [--sample_step SAMPLE_STEP]\n",
      "               [--max_samples MAX_SAMPLES] [--keep_punct] [--keep_sym]\n",
      "               [--identify_lang]\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  -f F                  optional list of features in json\n",
      "  -t T                  types of features (words or chars)\n",
      "  -n N                  n grams lengths (default 1)\n",
      "  -p P                  Processes to use (default 1)\n",
      "  -c C                  Path to file with metadata corrections\n",
      "  -k K                  How many most frequent?\n",
      "  --absolute_freqs      switch to get absolute instead of relative freqs\n",
      "  --z_scores            Use z-scores?\n",
      "  -s S [S ...]          paths to files\n",
      "  -x X                  format (txt, xml or tei)\n",
      "  --sampling            Sample the texts?\n",
      "  --sample_units SAMPLE_UNITS\n",
      "                        Units of length for sampling (words, verses; default:\n",
      "                        verses)\n",
      "  --sample_size SAMPLE_SIZE\n",
      "                        Size for sampling (default: 400)\n",
      "  --sample_step SAMPLE_STEP\n",
      "                        Step for sampling with overlap (default is no overlap)\n",
      "  --max_samples MAX_SAMPLES\n",
      "                        Maximum number of (randomly selected) samples per\n",
      "                        author (default is all) /!\\ Only with sampling\n",
      "  --keep_punct          whether or not to keep punctuation and caps (default\n",
      "                        is False)\n",
      "  --keep_sym            if true, same as keep_punct, plus no Unidecode, and\n",
      "                        numbers are kept as well (default is False)\n",
      "  --identify_lang       if true, should the language of each text be guessed,\n",
      "                        using a fasttext model (default is False) --\n",
      "                        Necessitates downloading the model\n"
     ]
    }
   ],
   "source": [
    "!python main.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "386d34fe-d87a-48ea-adda-9a9c254728a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......loading texts.......\n",
      ".......getting features.......\n",
      "K Limit ignored because the size of the list is lower (2490 < 5000)\n",
      ".......getting counts.......\n",
      ".......feeding data frame.......\n",
      "100%|█████████████████████████████████████████| 129/129 [00:04<00:00, 32.09it/s]\n",
      ".......applying normalisations.......\n",
      ".......saving results.......\n"
     ]
    }
   ],
   "source": [
    "# Different options for data\n",
    "# first, character n-grams\n",
    "!python main.py -s data/trouveres/train_cleaned_segm/*.txt -t chars -n 3 -x txt #--sampling --sample_units words --sample_size 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece00f9-e131-4c5e-8f5a-48b55779566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, affixes\n",
    "!python main.py -s data/trouveres/train_cleaned_segm/*.txt -t chars -n 3 -x txt #--sampling --sample_units words --sample_size 3000\n",
    "!python features_filter.py --affixes_grams -f feature_list_chars3grams5000mf.json\n",
    "!python main.py -s data/trouveres/train_cleaned_segm/*.txt -t chars -n 3 -x txt -f feature_list_chars3grams5000mf_affixes.json #--sampling --sample_units words --sample_size 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e15ba20-148e-4e40-8c3e-fc08603a9ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words\n",
    "!python main.py -s data/trouveres/train_cleaned_segm/*.txt -t words -n 1 -x txt #--sampling --sample_units words --sample_size 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d0a8b0-1cee-4718-b540-ae0c07711a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function words\n",
    "!python main.py -s data/trouveres/train_cleaned_segm/*.txt -t words -n 1 -x txt -f function_words.json #--sampling --sample_units words --sample_size 3000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e97de2-e297-4479-879d-c42d56e22ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmas\n",
    "!python main.py -s data/lem/train/*.txt -t words -n 1 -x txt #--sampling --sample_units words --sample_size 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c373e4b-1958-4fcf-8cbd-ee73568bb008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function lemmas\n",
    "!python main.py -s data/txt/train/*.txt -t words -n 1 -x txt -f function_lem.json # --sampling --sample_units words --sample_size 3000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9655ae1-fee6-4ce3-963a-dc32ec5da201",
   "metadata": {},
   "source": [
    "# Analyse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e36492-24cc-46c0-b4c4-abd431f093e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_svm.py [-h] [--test_path TEST_PATH]\n",
      "                    [--cross_validate {leave-one-out,k-fold,group-k-fold}]\n",
      "                    [--k K] [--dim_reduc {pca}] [--norms]\n",
      "                    [--balance {downsampling,Tomek,upsampling,SMOTE,SMOTETomek}]\n",
      "                    [--class_weights]\n",
      "                    [--kernel {LinearSVC,linear,polynomial,rbf,sigmoid}]\n",
      "                    [--final] [--get_coefs]\n",
      "                    train_path\n",
      "\n",
      "positional arguments:\n",
      "  train_path            Path to train file\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --test_path TEST_PATH\n",
      "                        Path to test file\n",
      "  --cross_validate {leave-one-out,k-fold,group-k-fold}\n",
      "                        perform cross validation (test_path will be used only\n",
      "                        for final prediction).If group_k-fold is chosen, each\n",
      "                        source file will be considered a group (only relevant\n",
      "                        if sampling was performed and more than one file per\n",
      "                        class was provided)\n",
      "  --k K                 k for k-fold\n",
      "  --dim_reduc {pca}     optional dimensionality reduction of input data (warn:\n",
      "                        som is broken)\n",
      "  --norms               perform normalisations? (default: True)\n",
      "  --balance {downsampling,Tomek,upsampling,SMOTE,SMOTETomek}\n",
      "                        which strategy to use in case of imbalanced datasets:\n",
      "                        downsampling (random without replacement), Tomek\n",
      "                        (downs. by removing Tomek links), upsampling (random\n",
      "                        over sampling with replacement), SMOTE (upsampling\n",
      "                        with SMOTE - Synthetic Minority Over-sampling\n",
      "                        Technique), SMOTETomek (over+undersampling with\n",
      "                        SMOTE+Tomek)\n",
      "  --class_weights       whether to use class weights in imbalanced datasets\n",
      "                        (inversely proportional to total class samples)\n",
      "  --kernel {LinearSVC,linear,polynomial,rbf,sigmoid}\n",
      "                        type of kernel to use (default LinearSVC; possible\n",
      "                        alternatives, linear, polynomial, rbf, sigmoid)\n",
      "  --final               final analysis on unknown dataset (no evaluation)?\n",
      "  --get_coefs           switch to write to disk and plots the most important\n",
      "                        coefficients for the training feats for each class\n"
     ]
    }
   ],
   "source": [
    "!python train_svm.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e580ea1a-2e4e-48f9-9981-4ff12c69095c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......... loading data ........\n",
      ".......... Formatting data ........\n",
      ".......... Creating pipeline according to user choices ........\n",
      ".......... using normalisations ........\n",
      ".......... choosing SVM ........\n",
      ".......... Creating pipeline with steps ........\n",
      "[('scaler', StandardScaler()), ('normalizer', Normalizer()), ('model', LinearSVC(class_weight='balanced'))]\n",
      ".......... leave-one-out cross validation will be performed ........\n",
      ".......... using 129 samples or groups........\n",
      "[Parallel(n_jobs=-1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 129 out of 129 | elapsed:  1.1min finished\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Blond       0.64      0.43      0.51        21\n",
      "        Gace       0.69      0.88      0.78        43\n",
      "        Gaut       0.71      0.60      0.65        20\n",
      "        Thib       0.98      0.93      0.95        45\n",
      "\n",
      "    accuracy                           0.78       129\n",
      "   macro avg       0.75      0.71      0.72       129\n",
      "weighted avg       0.79      0.78      0.78       129\n",
      "\n",
      ".......... Training final SVM with all train set ........\n"
     ]
    }
   ],
   "source": [
    "!python train_svm.py feats_tests_n3_k_5000.csv --cross_validate leave-one-out --class_weights --get_coefs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
